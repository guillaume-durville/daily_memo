## linux_cluster

1. http是无状态的

系统: 可扩展性, 高可用, 性能

构建高可扩展性的系统的原则; 系统内部尽量避免串行化和交互

HA: high availability
LB: load balancing 

memcached：key-value
redis: NoSQL

CDN: content delivery network

- 分布式:
分布式应用
分布式静态资源
分布式数据和存储
分布式计算

- 集群的类型:
LB: 扩展和伸缩
HA：高可用
HP：High Performance
	向量机,并行处理集群
	
LB的分类:
	软件:
		LVS(传输层),Haproxy/nginx(应用层)
	硬件:
		F5,Citrix netscaler, A10, Array,Redware
		
HA:
	heartbeat
	corosync+ pacemaker
	RHCS:cman+ rgmanager
	cman + pacemaker
	keeplived
	
HP:
	hadoop
	
2. LVS linux virtual server:
四层路由,四层交换; 根据目标地址和目标端口实现请求转发
netfilter: PREROUTING->INPUT->FORWARD->OUTPUT->POSTROUTING
iptables/netfilter

lvs: ipvsadm/ipvs

LVS的术语:
director/real server
VIP virtual IP
DIP Director IP
RIP Real Server IP
CIP Client IP

LVS的模式:
lvs-nat：nat类型的特性：
	RS应用使用私有地址；RS的网关必须指向DIP；
	请求和响应都要经过Director；高负载场景中，Director易成为性能瓶颈；
	支持端口映射；
	RS可以使用任意OS；
	
lvs-dr, dr类型的特性：
	保证前端路由将目标地址为VIP的报文统统发往Directory，而不能是RS；
	解决方案：
		(1) 静态地址绑定：在前端路由器上操作 , 问题：未必有路由操作权限
		(2) aprtables
		(3) 修改RS上内核参数，将RS上的VIP配置在lo接口的别名上，并限制其不能响应对VIP地址解析请求；
	RS可以使用私有地址；但也可以使用公网地址，此时可通过互联网通过RIP对其直接访问；
	RS跟Directory必须在同一物理网络中；
	请求报文经由Director，但响应报文必须不能经过Director；
	不支持端口映射；
	RS可以是大多数常见的OS；
    RS的网关绝不允许指向DIP；
	
lvs-tun, tun类型的特性:
	RIP、VIP、DIP全部是公网地址；
	RS的网关不会也不可能指向DIP；
	请求报文经由Director，但响应报文必须不能经过Director；
	不支持端口映射；
	RS的OS必须支持隧道功能；

- LVS的调度算法:
	rr, wrr加权轮询, sh源地址哈希,dh目标地址hash
	lc最少连接, wlc, nq, lblc, lblcr
	
- director负责定义集群服务,为集群添加RS
ipvsadm用法:
ipvsadm -L -n #查看进群服务和RS
ipvsadm -C  #清空集群服务
ipvsadm-save > file
ipvsadm-restore < file

- session持久机制
session绑定,来自同一个IP的请求定向至一个RS
session复制,在RS之间同步session
session服务器, 利用单独的服务器来统一管理集群中的session

- LVS-DR:
RS上配置内核参数:
	arp_ignore=1 #1表示仅在请求的地址配置在请求的报文接口进行响应
	arp_announce=2  #2表示仅通过网络直连的接口地址
配置VIP:
	ifconfig lo:0 VIP netmask 255.255.255.255 broadcast VIP up
	route add -host VIP dev lo:0
	
- Director脚本:
#!/bin/bash
#
# LVS script for VS/DR
#
. /etc/rc.d/init.d/functions
#
VIP=192.168.0.210
RIP1=192.168.0.221
RIP2=192.168.0.222
PORT=80

#
case "$1" in
start)           
  /sbin/ifconfig eth0:1 $VIP broadcast $VIP netmask 255.255.255.255 up
  /sbin/route add -host $VIP dev eth0:1

# Since this is the Director we must be able to forward packets
  echo 1 > /proc/sys/net/ipv4/ip_forward

# Clear all iptables rules.
  /sbin/iptables -F

# Reset iptables counters.
  /sbin/iptables -Z

# Clear all ipvsadm rules/services.
  /sbin/ipvsadm -C

# Add an IP virtual service for VIP 192.168.0.219 port 80
# In this recipe, we will use the round-robin scheduling method. 
# In production, however, you should use a weighted, dynamic scheduling method. 
  /sbin/ipvsadm -A -t $VIP:80 -s wlc

# Now direct packets for this VIP to
# the real server IP (RIP) inside the cluster
  /sbin/ipvsadm -a -t $VIP:80 -r $RIP1 -g -w 1
  /sbin/ipvsadm -a -t $VIP:80 -r $RIP2 -g -w 2

  /bin/touch /var/lock/subsys/ipvsadm &> /dev/null
;; 

stop)
# Stop forwarding packets
  echo 0 > /proc/sys/net/ipv4/ip_forward

# Reset ipvsadm
  /sbin/ipvsadm -C

# Bring down the VIP interface
  /sbin/ifconfig eth0:1 down
  /sbin/route del $VIP
  
  /bin/rm -f /var/lock/subsys/ipvsadm
  
  echo "ipvs is stopped..."
;;

status)
  if [ ! -e /var/lock/subsys/ipvsadm ]; then
    echo "ipvsadm is stopped ..."
  else
    echo "ipvs is running ..."
    ipvsadm -L -n
  fi
;;
*)
  echo "Usage: $0 {start|stop|status}"
;;
esac
	
	
- RealServer脚本:

#!/bin/bash
#
# Script to start LVS DR real server.
# description: LVS DR real server
#
.  /etc/rc.d/init.d/functions

VIP=192.168.0.219
host=`/bin/hostname`

case "$1" in
start)
	#Start LVS-DR real server on this machine.
	/sbin/ifconfig lo down
	/sbin/ifconfig lo up
	echo 1 > /proc/sys/net/ipv4/conf/lo/arp_ignore
	echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announce
	echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
	echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
	
	/sbin/ifconfig lo:0 $VIP broadcast $VIP netmask 255.255.255.255 up
	/sbin/route add -host $VIP dev lo:0

;;
stop)

    # Stop LVS-DR real server loopback device(s).
    /sbin/ifconfig lo:0 down
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/lo/arp_announce
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce

;;
status)
    # Status of LVS-DR real server.
    islothere=`/sbin/ifconfig lo:0 | grep $VIP`
    isrothere=`netstat -rn | grep "lo:0" | grep $VIP`
    if [ ! "$islothere" -o ! "isrothere" ];then
        # Either the route or the lo:0 device
        # not found.
        echo "LVS-DR real server Stopped."
    else
        echo "LVS-DR real server Running."
    fi
;;
*)
    # Invalid entry.
    echo "$0: Usage: $0 {start|status|stop}"
    exit 1
;;
esac
	
	
3. 在CentOS6.5上使用lxc虚拟机
- 解决依赖
yum install -y libcgroup
service cgconfig start

- 虚拟网桥接口	
vi /etc/sysconfig/network-scripts/ifcfg-br0	
DEVICE=br0
TYPE=Bridge
BOOTPROTO=static
IPADDR=172.16.100.7
NETMASK=255.255.0.0
GATEWAY=172.16.0.1
ONBOOT=yes
DELAY=0
NM_CONTROLLED=no

- 桥接物理网卡eth0到br0
vi /etc/sysconfig/network-script/ifcfg-eth0	
DEVICE="eth0"
BOOTPROTO="static"
NM_CONTROLLED="no"
ONBOOT="yes"
TYPE="Ethernet"
BRIDGE=br0
...

service network restart

- 安装lxc
yum install lxc-1.0.5-1.el6.x86_64.rpm lxc-libs-1.0.5-1.el6.x86_64.rpm

- 检查lxc运行环境
lxc-checkconfig

- 创建centos虚拟机
lxc为创建虚拟机提供了模板,/usr/share/lxc/templates
lxc为虚拟机提供的默认配置文件为/etc/lxc/default.conf
lxc.network.type = veth
lxc.network.link = br0
lxc.network.flags = up

- 创建虚拟机
lxc-create -n centos -t /usr/share/lxc/templates/lxc-centos

- 启动目标系统centos
lxc-start -n centos


- RS健康状态检查脚本：
#!/bin/bash
#
VIP=192.168.10.3
CPORT=80
FAIL_BACK=127.0.0.1
FBSTATUS=0
RS=("192.168.10.7" "192.168.10.8")
RSTATUS=("1" "1")
RW=("2" "1")
RPORT=80
TYPE=g

add() {
  ipvsadm -a -t $VIP:$CPORT -r $1:$RPORT -$TYPE -w $2
  [ $? -eq 0 ] && return 0 || return 1
}

del() {
  ipvsadm -d -t $VIP:$CPORT -r $1:$RPORT
  [ $? -eq 0 ] && return 0 || return 1
}

while :; do
  let COUNT=0
  for I in ${RS[*]}; do
    if curl --connect-timeout 1 http://$I &> /dev/null; then
      if [ ${RSTATUS[$COUNT]} -eq 0 ]; then
         add $I ${RW[$COUNT]}
         [ $? -eq 0 ] && RSTATUS[$COUNT]=1
      fi
    else
      if [ ${RSTATUS[$COUNT]} -eq 1 ]; then
         del $I
         [ $? -eq 0 ] && RSTATUS[$COUNT]=0
      fi
    fi
    let COUNT++
  done
  sleep 5
done
	
	
#version2	
#!/bin/bash
#
VIP=192.168.10.3
CPORT=80
FAIL_BACK=127.0.0.1
RS=("192.168.10.7" "192.168.10.8")
declare -a RSSTATUS
RW=("2" "1")
RPORT=80
TYPE=g
CHKLOOP=3
LOG=/var/log/ipvsmonitor.log

addrs() {
  ipvsadm -a -t $VIP:$CPORT -r $1:$RPORT -$TYPE -w $2
  [ $? -eq 0 ] && return 0 || return 1
}

delrs() {
  ipvsadm -d -t $VIP:$CPORT -r $1:$RPORT 
  [ $? -eq 0 ] && return 0 || return 1
}

checkrs() {
  local I=1
  while [ $I -le $CHKLOOP ]; do 
    if curl --connect-timeout 1 http://$1 &> /dev/null; then
      return 0
    fi
    let I++
  done
  return 1
}

initstatus() {
  local I
  local COUNT=0;
  for I in ${RS[*]}; do
    if ipvsadm -L -n | grep "$I:$RPORT" && > /dev/null ; then
      RSSTATUS[$COUNT]=1
    else 
      RSSTATUS[$COUNT]=0
    fi
  let COUNT++
  done
} 

initstatus
while :; do
  let COUNT=0
  for I in ${RS[*]}; do
    if checkrs $I; then
      if [ ${RSSTATUS[$COUNT]} -eq 0 ]; then
         addrs $I ${RW[$COUNT]}
         [ $? -eq 0 ] && RSSTATUS[$COUNT]=1 && echo "`date +'%F %H:%M:%S'`, $I is back." >> $LOG
      fi
    else
      if [ ${RSSTATUS[$COUNT]} -eq 1 ]; then
         delrs $I
         [ $? -eq 0 ] && RSSTATUS[$COUNT]=0 && echo "`date +'%F %H:%M:%S'`, $I is gone." >> $LOG
      fi
    fi
    let COUNT++
  done 
  sleep 5
done	
	
	
4. HA：高可用
提高系统的可用性:
	缩短平均修复时间
集群:
	手动/自动切换failover
资源:
	vip/ipvs规则
	
- 解决方案:
vrrp+script: keeplived
heartbeat/corosync/cman

HA的框架:
message layer: 基础事务层
CRM: cluster resource manager, heartbest v3版本=heartbeat+pacemaker+cluster-glue
	cman+ rgmanager
LRM: local resource manager
RA: resource agent

- CentOS6的高可用集群方案:
RHCS: cman+rgmanager
corosync + rgmanager
cman + pacemaker
heartbeat v3 + pacemaker
keepalived

- 配置高可用的前提
时间同步ntp服务器
节点名称互相通信/etc/hosts, uname -n
ping node
ssh密钥认证


==================================================================================================================


5. ansible
是agentless的基于ssh实现,fabric
幂等性

ansible host-pattern -m module -a "args"

- ansible的模块
command
user
copy
cron
file
filesystem
group
hostname
ping
yum
service
shell
script

ansible-doc -l  #帮助

- playbook：
Tasks 任务: 各模块所支持执行的特定操作
	-m user -a "name= password="
Variables变量：
Templates模板:
	文本文件模板
Handlers：处理器 事先定义好的可以在某些条件出发
Roles:角色 
	层次型组织playbook及其所依赖的各种资源的机制
	

6. mysql+ drbd + corosync

7. nginx
web服务器
http,mail反向代理proxy

keepalived高可用反向代理nginx，双主模型高可用ipvs




	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
