https://jimmysong.io/kubernetes-handbook/concepts/

kubernetes-handbook读书笔记


1. kunernetes架构
kubernetes最初源于google内部的Borg, Kubernetes 具备完善的集群管理能力，包括多层次的安全防护和准入机制、
多租户应用支撑能力、透明的服务注册和服务发现机制、内建负载均衡器、故障发现和自我修复能力、服务滚动升级和在线扩容、
可扩展的资源自动调度机制、多粒度的资源配额管理能力。 
Kubernetes 还提供完善的管理工具，涵盖开发、部署测试、运维监控等各个环节。

kubernetes主要由以下核心组件组成:
- etcd保存整个集群状态
- apiserver提供集群资源操作的唯一入口,提供认证、授权、访问控制、API注册和发现等机制
- controller manager负责资源的调度,按照预定的调度策略将Pod调度到相应的机器上
- kubelet负责维护容器的生命周期,也负责volume(CSI)和网络(CNI)的管理
- container runtime负责镜像管理以及Pod的容器运行(CRI)
- kube-proxy负责为service提供cluster内部的服务发现和负载均衡

除了核心组件还有CNCF推荐的插件add-on:
- CoreDNS负责为集群提供DNS服务
- Ingress Controller为服务提供外网入口
- Prometheus提供资源监控
- Dashboard提供GUI
- Federation提供跨可用区的集群


1.1 kubernetes设计理念
分层架构
高内聚、松耦合

1.1.1 kubernetes的核心技术概念和API对象
每个API对象都有3个类属性:
- 元数据metadata、用来标记API对象: namespace+name+uid+label等
- 规范spec、描述了用户期望集群中分布式系统的理想状态desired state
- 状态status,描述了系统实际达到的状态

声明式declarative操作比命令式imperative更稳定、不怕丢操作或运行多次

- Pod：
是k8s集群中运行部署应用或服务的最小单位,可以支持多容器,pod内的容器共享网络地址和文件系统

- Deployment: 
表示对集群的一次更新操作,部署是一个比RS应用模式更广的API对象，可以是创建一个新的服务，更新一个新的服务，
也可以是滚动升级一个服务。滚动升级一个服务，实际是创建一个新的RS，然后逐渐将新RS中副本数增加到理想状态，将旧RS中的副本数减小到0的复合操作long-running长期伺服型业务

- Replication controller(RC): 
保证pod高可用的对象,保持执行的副本数量 

- Replica Set(RS): 
是新一代的RC,同样提供高可用能力,支持更多的匹配模式

- 服务Service：
RC、RS、Deployment只是保证了支撑服务的微服务Pod数量,没有解决服务访问问题
服务发现就是针对客户端访问的服务,找到对象的后端服务实例
Service对应一个集群内部有效的虚拟IP,集群内部通个这个虚拟IP访问服务
Kube-proxy来实现服务的负载均衡,它是一个分布式代理服务器

- 任务Job：
是用来控制批处理型任务的API对象

- 后台支持服务集DaemonSet:
保证每个节点都有此类Pod运行,节点可能是通过nodeSelector选定的一些特定节点
典型的DaemonSet有:存储、日志和监控等服务

- 有状态的服务集StatefulSet：
用来控制有状态的服务,每个pod名字都是事先确定的,不能更改
适合statefulSet的业务包括: MySQL和PostgreSQL,集群化管理服务Zookeeper、etcd等
StatefulSet的另一种典型应用场景是作为一种比普通容器更稳定可靠的模拟虚拟机的机制
StatefulSet保证确定的Pod和确定的存储关联起来保证状态的连续性

- 集群联邦Federation：
提供跨Region跨服务商的集群服务
cluster的负载均衡通过域名服务的负载均衡来实现

- 存储卷Volume：
类似Docker的存储卷,只是kubernetes的存储卷生命周期和作用范围是一个Pod
支持多种公有云平台存储
支持多种分布式存储包括GlusterFS和Ceph
支持较容易使用的主机目录emptyDir,hostPath和NFS
还支持Persistent Volume Claim即PVC这种逻辑存储,

- 持久存储卷PV和持久存储卷声明PVC:
PV和PVC使得kubernetes集群具备了存储的逻辑抽象能力,使得配置Pod的逻辑里可以忽略对实际后台
存储技术的配置,而将配置工作交给PV的配置者,
PV是资源提供者,PVC是资源使用者

- 节点Node：
最初成为Minion
Node相当于Mesos的Slave节点,是Pod运行所在的工作主机,可以是物理机也可以是虚拟机

- 密钥Secret：
用来保存和传递密码、密钥、认证凭证这些敏感信息的对象
避免将明文写在配置文件中,可以将这些信息存入一个Secret对象,

- 用户帐户User Account和服务帐户Service Account:
用户帐户为人提供账户标识,而服务帐户为计算机进程和pid提供账户标识
用户帐户对应的是人的身份,人的身份和服务的namesapce无关
服务帐户对应的是一个运行中程序的身份,与特定namespace相关的

- 命名空间namespace:
命名空间为集群提供虚拟的隔离作用,kubernetes初始有两个命名空间,分别是默认的命令空间default
和系统命令空间kube-system,管理员可以创建新的命名空间满足需要

- RBAC访问授权:
Role-based Access Contorl的授权模式,相对于基于属性的访问控制ABAC
RBAC引入了角色Role和角色绑定RoleBinding的抽象概念
ABAC的访问策略只能和用户直接关联,RBAC这一新的概念抽象使的集群服务管理
和使用更容器扩展和重用


- 总结：
Kubernetes系统最核心的两个设计理念：一个是容错性，一个是易扩展性
按照分布式系统一致性算法Paxos发明人计算机科学家Leslie Lamport的理念，
一个分布式系统有两类特性：安全性Safety和活性Liveness


1.2 Etcd解析
etcd是kubernetes集群中一个十分重要的组件,用于保存集群所有网络配置和对象的状态信息
- 网络插件flannel、对于其他网络插件也需要用到etcd存储网络的信息
- kubernetes本身,包括各种对象的状态和元信息配置

etcd的原理:
etcd使用raft一致性算法来实现的,是一款分布式的一致性KV存储,用于共享配置和服务发现

使用etcd存储flannel网络信息:
etcdctl --ca-file=/etc/kubernetes/ssl/ca.pem \  #查看etcd中存储的flannel网络信息
--cert-file=/etc/kubernetes/ssl/kubernetes.pem \
--key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
ls /kube-centos/network -r

etcdctl --ca-file=/etc/kubernetes/ssl/ca.pem \  #查看flannel的配置
--cert-file=/etc/kubernetes/ssl/kubernetes.pem \
--key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
get /kube-centos/network/config


使用etcd存储kubernetes对象信息:

查看集群所有Pod信息:
ETCDCTL_API=3 etcdctl get /registry/pods --prefix -w json|python -m json.tool

Etcd V2与V3版本API的区别：
Etcd V2和V3之间的数据结构完全不同，互不兼容
这就造成我们访问etcd中保存的flannel的数据需要使用etcdctl的V2版本的客户端，而访问kubernetes的数据需要设置ETCDCTL_API=3环境变量来指定V3版本的API


Etcd数据备份：
Etcd数据的存储路径是/var/lib/etcd，一定要对该目录做好备份

1.3 开放接口
Kubernetes作为云原生应用的基础调度平台,相当于云原生的操作系统,为了方便扩展
kubernetes开发了以下接口: 可以对接不同的后端来实现业务逻辑
- CRI:容器运行时接口,提供计算资源
定义了容器和镜像的服务接口,容器运行时和镜像的生命周期是彼此隔离的
该接口使用protocol bufffer基于gRPC
CRI实现了CRI gRPC Server包括runtimeserver和imageservice,
gRPC server需要监听本地的Unix socket
kubelet则作为gRPC Client运行

支持的CRI后端:
cri-o: 兼容OCI和CRI的容器运行时
cri-containerd: 基于containerd和kubernetes CRI实现
rkt：CoreOS主推的容器运行时
docker：还没有从kubelet中解耦等

- CNI:容器网络接口,通过网络资源
是CNCF下的一个项目,由一组用于配置容器网络接口的规范和库组成
CNI插件负责将网络接口插入容器网络命名空间（例如，veth对的一端），并在主机上进行任何必要的改变（例如将veth的另一端连接到网桥）
然后将IP分配给接口，并通过调用适当的IPAM插件来设置与“IP地址管理”部分一致的路由

- CSI:容器存储接口,提供存储资源
代表容器存储接口,CSI试图建立一个行业标准接口的规范


2. kubernetes的网络
kubernetes本身不提供网络功能,只是将网络接口开发出来,通过插件的形式实现

节点上的进程是按照flannel -> docker -> kubelet -> kube-proxy的顺序启动的

3. 资源对象的概念
分类为以下几种资源对象：
资源对象 	Pod、ReplicaSet、ReplicationController、Deployment、StatefulSet、DaemonSet、Job、CronJob、HorizontalPodAutoscaling、Node、Namespace、Service、Ingress、Label、CustomResourceDefinition
存储对象 	Volume、PersistentVolume、Secret、ConfigMap
策略对象 	SecurityContext、ResourceQuota、LimitRange
身份对象 	ServiceAccount、Role、ClusterRole

3.1 对象的理解
这些对象是持久化的条目,k8s使用这些条目去表示整个集群的状态
主要描述的信息有:
- 什么容器什么应用及哪一个Node
- 应用使用的资源
- 关于应用如何表现的策略,重启/升级/容错等策略

kubernetes对象是目标性记录,一旦创建对象,集群将持续工作确保对象的存在,保证集群期望状态

对象spec和状态status:
描述对象:
在yaml格式文件中定义这些信息,
示例:
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
		
kubectl create -f docs/user-guide/nginx-deployment.yaml --record #创建一个deployment

必需字段:
apiVersion
kind  #创建对象类型
metadata  #识别对象的唯一性数据


		
4. Pod状态和生命周期管理
Kubernetes中的基本组件kube-controller-manager就是用来控制Pod的状态和生命周期的

4.1 pod概述
pod代表集群中的进程
pod中封装着部署应用容器,存储、网络等

一个pod中可以封装多个紧密耦合相互协作的容器,他们共享资源

如何管理多个容器:
k8s使用controller来管理pod实例
controller可以创建和管理多个pod,提供副本管理、滚动升级和集群级别的自愈能力

常见的controller有:
Deployment
StatefulSet
DaemonSet

pod模板包含了pod的定义
pod像豌豆荚,由一个或者多个容器组成（例如Docker容器），它们共享容器存储、网络和容器运行配置项
Pod中的容器总是被同时调度，有共同的运行环境

Pod中共享的环境包括Linux的namespace、cgroup和其他可能的隔绝环境
Pod中的容器共享IP地址和端口号，它们之间可以通过localhost互相发现。它们之间可以通过进程间通信，例如SystemV信号或者POSIX共享内存

Pod中的容器也有访问共享volume的权限，这些volume会被定义成pod的一部分并挂载到应用容器的文件系统中

通常，用户不需要手动直接创建Pod，而是应该使用controller（例如Deployments），即使是在创建单个Pod的情况下。
Controller可以提供集群级别的自愈功能、复制和升级管理。

4.2 init容器
4.3 pause容器
pause容器主要:
在pod中担任Linux命名空间共享的基础
启用pid命名空间,开启init进程

4.4 pod的安全策略
PodSecurityPolicy
创建 Pod 安全策略 psp.yaml  
  
apiVersion: extensions/v1beta1
kind: PodSecurityPolicy
metadata:
  name: permissive
spec:
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  runAsUser:
    rule: RunAsAny
  fsGroup:
    rule: RunAsAny
  hostPorts:
  - min: 8000
    max: 8080
  volumes:
  - '*'
  
kubectl create -f ./psp.yaml  
  
kubectl get psp #获取podsercuritypolicy
kubectl edit psp permissive
kubectl delete psp permissive

使用RBAC
当 Pod 基于 Deployment、ReplicaSet 创建时，它是创建 Pod 的 Controller Manager

4.5 pod的生命周期
pod的phase是pod在其生命周期中的简单宏观概述
Pending,等待容器创建
Running, pod已绑定到一个节点上,
Successed, pod中的容器都成功终止
Failed, 至少一个容器因失败终止
Unknown, 无法获取pod状态

Pod状态:
PodStatus对象

容器探针是kubelet对容器执行定期诊断:
1.ExecAction,容器内部执行指定的命令
2.TCPSocketAction, 指定端口上的容器IP地址进行TCP检查
3.HTTPGetAction, GTTP Get请求状态码200-400则成功

重启策略:
PodSpec中有一个restartPolicy字段,可能值有Always、OnFailure、Never
restartPolicy 仅指通过同一节点上的 kubelet 重新启动容器

4.6 Pod Preset：
Preset 就是预设，有时候想要让一批容器在启动的时候就注入一些信息，比如 secret、volume、volume mount 和环境变量

4.7 Pod中断和PDB(Pod中断预算)
自愿中断:

程序所有者操作包括：
    删除管理该 pod 的 Deployment 或其他控制器
    更新了 Deployment 的 pod 模板导致 pod 重启
    直接删除 pod（意外删除）

集群管理员操作包括：
    排空（drain）节点进行修复或升级。
    从集群中排空节点以缩小集群（了解集群自动调节）。
    从节点中移除一个 pod，以允许其他 pod 使用该节点。

处理中断:
应用程序所有者可以为每个应用程序创建一个 PodDisruptionBudget 对象（PDB）
PDB 将限制在同一时间自愿中断的复制应用程序中宕机的 Pod 的数量

5. 集群资源管理
5.1 node
node是集群工作节点,物理机或虚拟机

- node的状态
Address:
	Hostname、ExternalIP、InternalIP
Condition:
	OutOfDisk、Ready、MemoryPressure、DiskPressure
Capacity:
	CPU、内存、可运行最大的Pod数量
Info：
	节点版本信息
	
- node管理：
kubectl cordon <node>  #禁止pod调度到该节点
kubectl drain <node>   #驱逐该节点上所有的pod,通常该节点需要维护时使用该命令
kubectl uncordon <node>  #即可将该节点添加到kubernetes集群中

5.2 namespace:
集群使用namespace创建多个"虚拟集群",这些namespace可以完全隔离

例如生产、测试、开发划分不同的namespace

- namespace的使用：
kubectl get ns

5.3 Label
label是附着到object上的键值对,可以创建object时指定
label能够将组织架构映射到系统架构上(康威定律),
常用的标签:
    "release" : "stable", "release" : "canary"
    "environment" : "dev", "environment" : "qa", "environment" : "production"
    "tier" : "frontend", "tier" : "backend", "tier" : "cache"
    "partition" : "customerA", "partition" : "customerB"
    "track" : "daily", "track" : "weekly"
    "team" : "teamA","team:" : "teamB"

- Label selector
Label不是唯一的,通过label selector,客户端/用户可以指定一个object集合
通过label selector对object的集合进行操作
示例:
kubectl get pods -l environment=production,tier=frontend
kubectl get pods -l 'environment in (production),tier in (frontend)'
kubectl get pods -l 'environment in (production, qa)'
kubectl get pods -l 'environment,environment notin (frontend)'

- API object中设置label selector
在service、replicationcontroller等object中有对pod的label selector，使用方法只能使用等于操作，例如：
selector:
    component: redis

在Job、Deployment、ReplicaSet和DaemonSet这些object中，支持set-based的过滤，例如：
selector:
  matchLabels:
    component: redis
  matchExpressions:
    - {key: tier, operator: In, values: [cache]}
    - {key: environment, operator: NotIn, values: [dev]}

5.4 annnotation注解

- 关联元数据到对象
Label和Annotation都可以将元数据关联到Kubernetes资源对象。
Label主要用于选择对象，可以挑选出满足特定条件的对象。相比之下，annotation 不能用于标识及选择对象

annotation和label一样都是key/value键值对映射结构：
"annotations": {
  "key1" : "value1",
  "key2" : "value2"
}

5.5 Taint和Toleration(污点和容忍)
Taint 和 toleration 相互配合，可以用来避免 pod 被分配到不合适的节点上。
每个节点上都可以应用一个或多个 taint ，这表示对于那些不能容忍这些 taint 的 pod，是不会被该节点接受的
toleration 应用于 pod 上，则表示这些 pod 可以（但不要求）被调度到具有相应 taint 的节点上

- 为node设置taint
kubectl taint nodes node1 key1=value1:NoSchedule
kubectl taint nodes node1 key1=value1:NoExecute
kubectl taint nodes node1 key2=value2:NoSchedule

#删除taint
kubectl taint nodes node1 key1:NoSchedule-
kubectl taint nodes node1 key1:NoExecute-
kubectl taint nodes node1 key2:NoSchedule-

#查看taint
kubectl describe nodes node1

- 为pod设置toleration
tolerations:
- key: "key1"
  operator: "Equal"
  value: "value1"
  effect: "NoSchedule"
- key: "key1"
  operator: "Equal"
  value: "value1"
  effect: "NoExecute"
- key: "node.alpha.kubernetes.io/unreachable"
  operator: "Exists"
  effect: "NoExecute"
  tolerationSeconds: 6000
  
5.6 垃圾回收
垃圾收集器负责删除指定对象  
  
kubectl delete replicaset my-repset --cascade=false

6. 控制Controller Manager
控制器controller相当于状态机,控制pod的具体状态和行为

6.1 Deployment
deployment为pod和replicaSet提供声明式declarative方法,用来替换之前的replicationController
- 应用场景
定义deployment来创建pod和replicaSet
滚动升级和回滚应用
扩容和缩容
暂停和继续deployment

一个简单的nginx定义:
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
		
kubectl scale deployment nginx-deployment --replicas=4  #扩容
kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80

kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1  #更换镜像版本
kubectl rollout undo deployment/nginx-deployment  #回滚

- Deployment是什么
在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态		

- 创建Deployment
kubectl create -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record
kubectl get deployments
kubectl get rs
kubectl get pods
kubectl get pods --show-labels

- 更新Deployment
Deployment 的 rollout 当且仅当 Deployment 的 pod template（例如.spec.template）中的label更新或者镜像更改时被触发
其他更新，例如扩容Deployment不会触发 rollout

kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1
kubectl edit deployment/nginx-deployment
kubectl rollout status deployment/nginx-deployment #查看rollout状态
kubectl get deployments
kubectl get rs
kubectl get pods


- rollover(多个rollout并行)

- label selector更新:

- 回退Deployment
kubectl rollout history deployment/nginx-deployment  #Deployment 的 revision
kubectl rollout history deployment/nginx-deployment --revision=2
kubectl rollout undo deployment/nginx-deployment  #回退历史版本
kubectl rollout undo deployment/nginx-deployment --to-revision=2  #指定某个历史版本

- 扩容deployment
kubectl scale deployment nginx-deployment --replicas 10
kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80

- 比例扩容
例如，您正在运行中含有10个 replica 的 Deployment。maxSurge=3，maxUnavailable=2

- 暂停和恢复deployment
kubectl rollout pause deployment/nginx-deployment
kubectl set image deploy/nginx nginx=nginx:1.9.1
kubectl rollout history deploy/nginx
kubectl set resources deployment nginx -c=nginx --limits=cpu=200m,memory=512Mi

kubectl rollout resume deploy nginx  #恢复这个Deployment
kubectl get rs -w


用例:
- 金丝雀deployment
使用 Deployment 对部分用户或服务器发布 release，您可以创建多个 Deployment，每个 Deployment 对应一个 release，
参照 managing resources 中对金丝雀模式的描述

6.2 StatefulSet
解决有状态的服务,应用场景有:
- 稳定的持久化存储,即pod重新调度后还能访问到相同的持久化数据,基于PVC实现
- 稳定的网络标志,podname和hostname不变,基于headless service来实现是
- 有序的部署,有序扩展, 基于init container来实现
- 有序的收缩、有序的删除 
每个Pod的DNS格式为 statefulSetName-{0..N-1}.serviceName.namespace.svc.cluster.local


- 使用statefulset
适于用: 稳定有序的网络标志、稳定持久化的存储、有序部署的scale、有序删除和终止、有序自动的滚动升级


- 组件
示例
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None
  selector:
    app: nginx
---
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: web
spec:
  serviceName: "nginx"
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      terminationGracePeriodSeconds: 10
      containers:
      - name: nginx
        image: gcr.io/google_containers/nginx-slim:0.8
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
  - metadata:
      name: www
      annotations:
        volume.beta.kubernetes.io/storage-class: anything
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
		  
		  



































